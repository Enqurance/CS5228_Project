{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9139239be4d3d26a",
   "metadata": {},
   "source": [
    "<img src=\"images/img.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a5ce1aa953b915",
   "metadata": {},
   "source": [
    "# CS5228 Project, Group 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5287322f-3943-4058-8448-970302c9ff79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Auto reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f32f076115be79",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "In this part, we are going to perform some data preprocessing steps. This may include:\n",
    "* Data cleaning: handle missing values, duplicates, inconsistant or invalid vallues, outliers\n",
    "\n",
    "* Data reduction: reduce number of attributes, reduce number of attribute values\n",
    "\n",
    "* Data transformation: attribute construction, normalization\n",
    "\n",
    "* Data discretization: encode to numerical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773fb74f",
   "metadata": {},
   "source": [
    "### Setting up the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a8c6d3e9adfc751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a084ae15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 25000 data points in training data, each with 30 attributes.\n"
     ]
    }
   ],
   "source": [
    "# Load file into pandas dataframe\n",
    "df = pd.read_csv('./data/train.csv')\n",
    "\n",
    "num_records, num_attributes = df.shape\n",
    "print(\"There are {} data points in training data, each with {} attributes.\". format(num_records, num_attributes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd41045",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389b04ed",
   "metadata": {},
   "source": [
    "Before data cleaning, remove the known attributes that are not meaningful to our prediction model:\n",
    "  * Meaningless idendifier: listing_id \n",
    "  * Attributes in free text: title, description, features, accessories\n",
    "  * Attribute with the same value: eco_category, indicative_price\n",
    "  * Attribute unlikely to affect price: curb_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c02d46d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 25000 data points in training data, each with 20 attributes.\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [\n",
    "    'listing_id',          # Meaningless identifier\n",
    "    'title',               # Attributes in free text\n",
    "    'description',\n",
    "    'features',\n",
    "    'accessories',\n",
    "    'eco_category',        # Attribute with the same value\n",
    "    'indicative_price',\n",
    "    'curb_weight',         # Attribute unlikely to affect price\n",
    "    'original_reg_date',\n",
    "    'lifespan',\n",
    "]\n",
    "\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "num_records, num_attributes = df.shape\n",
    "print(\"There are {} data points in training data, each with {} attributes.\". format(num_records, num_attributes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde0aaf8",
   "metadata": {},
   "source": [
    "### Handle Missing Values\n",
    "Firstly, for each of the columns with missing value, check the number of rows with NaN values.\n",
    "There are 3 scenarios:\n",
    "1. NaN value is the major (e.g. fuel_type has 19121 rows with NaN values), we remove the corresponding attritubes.\n",
    "2. NaN value is the minor. We can choose to fill or delete related data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "834807be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n",
      "Column 'make' has 1316 rows with NaN values.\n",
      "Column 'fuel_type' has 19121 rows with NaN values.\n",
      "Column 'manufactured' has 7 rows with NaN values.\n",
      "Column 'power' has 2640 rows with NaN values.\n",
      "Column 'engine_cap' has 596 rows with NaN values.\n",
      "Column 'mileage' has 5304 rows with NaN values.\n",
      "Column 'no_of_owners' has 18 rows with NaN values.\n",
      "Column 'depreciation' has 507 rows with NaN values.\n",
      "Column 'road_tax' has 2632 rows with NaN values.\n",
      "Column 'dereg_value' has 220 rows with NaN values.\n",
      "Column 'omv' has 64 rows with NaN values.\n",
      "Column 'arf' has 174 rows with NaN values.\n",
      "Column 'opc_scheme' has 24838 rows with NaN values.\n"
     ]
    }
   ],
   "source": [
    "columns_to_check = [\n",
    "    'make',\n",
    "    'fuel_type',\n",
    "    'manufactured',\n",
    "    'power',\n",
    "    'engine_cap',\n",
    "    'mileage',\n",
    "    'no_of_owners',\n",
    "    'depreciation',\n",
    "    'road_tax',\n",
    "    'dereg_value',\n",
    "    'omv',\n",
    "    'arf',\n",
    "    'opc_scheme'\n",
    "]\n",
    "\n",
    "# Calculate the number of NaN values in each specified column\n",
    "nan_counts = df[columns_to_check].isna().sum()\n",
    "\n",
    "# Print the number of NaN values for each column\n",
    "print('Training data')\n",
    "for column, count in nan_counts.items():\n",
    "    print(f\"Column '{column}' has {count} rows with NaN values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116b0e50",
   "metadata": {},
   "source": [
    "We delete attributes with TOO many NaN value here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da6b4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop_nan = [\n",
    "    'fuel_type',\n",
    "    'opc_scheme'\n",
    "]\n",
    "\n",
    "df = df.drop(columns=columns_to_drop_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea8a0de",
   "metadata": {},
   "source": [
    "Then we try to fill up other missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dfc6a526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values after handling:  0\n"
     ]
    }
   ],
   "source": [
    "from util.DataPreprocess import HandlingMissingValues\n",
    "\n",
    "df = HandlingMissingValues(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eafaf03",
   "metadata": {},
   "source": [
    "### Remove Exact Duplicates\n",
    "We remove duplicated data points here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8caa0e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24258 data points in training data, each with 18 attributes.\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "\n",
    "num_records, num_attributes = df.shape\n",
    "print(\"There are {} data points in training data, each with {} attributes.\". format(num_records, num_attributes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84de8476-6545-4f89-ad57-b891986a9045",
   "metadata": {},
   "source": [
    "### Merge rows with fewer data points on specific attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28900a18-8bf3-4516-b663-c00533fde54f",
   "metadata": {},
   "source": [
    "### Transform categorical value to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "829f7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    'make',\n",
    "    'model',\n",
    "    'type_of_vehicle',\n",
    "    'transmission',\n",
    "]\n",
    "\n",
    "encode_dict = {}\n",
    "le = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "    encode_dict[column] = {str(label): int(index) for index, label in enumerate(le.classes_)}\n",
    "\n",
    "with open('./data/encode.json', 'w') as file:\n",
    "    json.dump(encode_dict, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a273d568",
   "metadata": {},
   "source": [
    "### Transform date time attributes to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f580a7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24258 data points, each with 18 attributes.\n"
     ]
    }
   ],
   "source": [
    "df['reg_date'] = pd.to_datetime(df['reg_date'], format='%d-%b-%Y')\n",
    "df['reg_year'] = df['reg_date'].dt.year\n",
    "df = df.drop(columns=['reg_date'])\n",
    "\n",
    "num_records, num_attributes = df.shape\n",
    "print(\"There are {} data points, each with {} attributes.\". format(num_records, num_attributes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a29cd1d",
   "metadata": {},
   "source": [
    "### Handle category attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a43ae4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique categories: 15\n",
      "Unique categories: {'parf car', 'opc car', 'electric cars', 'premium ad car', 'imported used vehicle', 'sgcarmart warranty cars', 'coe car', 'consignment car', 'direct owner sale', 'vintage cars', 'hybrid cars', 'sta evaluated car', 'almost new car', 'rare & exotic', 'low mileage car'}\n",
      "There are 24258 data points, each with 32 attributes.\n"
     ]
    }
   ],
   "source": [
    "from util.DataPreprocess import HandlingCategoryAttribute\n",
    "\n",
    "df = HandlingCategoryAttribute(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a55c35-f9f7-42ed-a7aa-1e3edfffa7d4",
   "metadata": {},
   "source": [
    "### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c95ae45d-0846-4e1b-9f4d-2608349504b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from util.DataPreprocess import OutlierRemoval\n",
    "\n",
    "# df = OutlierRemoval(df, 'model', 'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11789885",
   "metadata": {},
   "source": [
    "### Saving the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "10b15971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing file './data/train_preprocessed.csv' has been deleted.\n",
      "DataFrame has been saved to './data/train_preprocessed.csv'.\n"
     ]
    }
   ],
   "source": [
    "file_name = './data/train_preprocessed.csv'\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_name):\n",
    "    # Delete the file\n",
    "    os.remove(file_name)\n",
    "    print(f\"Existing file '{file_name}' has been deleted.\")\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "df.to_csv(file_name, index=False)\n",
    "print(f\"DataFrame has been saved to '{file_name}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bc5a63",
   "metadata": {},
   "source": [
    "## Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a1b610-13c2-4709-9ad9-cb3482c3d209",
   "metadata": {},
   "source": [
    "### Load preprocessed training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "e6e80ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24258 data points in training data, each with 17 attributes.\n"
     ]
    }
   ],
   "source": [
    "# Load file into pandas dataframe, we saved our preprocessed file at path 'output_file'\n",
    "training_file = './data/train_preprocessed.csv'\n",
    "df = pd.read_csv(training_file)\n",
    "\n",
    "columns_to_keep = [\n",
    "    'model',\n",
    "    'mileage',\n",
    "    'low mileage car',\n",
    "    'manufactured',\n",
    "    'reg_year',\n",
    "    'type_of_vehicle',\n",
    "    'dereg_value',\n",
    "    'depreciation',\n",
    "    'power',\n",
    "    'coe',\n",
    "    'arf',\n",
    "    'omv',\n",
    "    'price',\n",
    "    'road_tax',\n",
    "    'almost new car',\n",
    "    'coe car',\n",
    "    'parf car',\n",
    "]\n",
    "\n",
    "df = df[columns_to_keep]\n",
    "columns_to_keep = [col for col in df.columns if col != 'price']\n",
    "\n",
    "num_records, num_attributes = df.shape\n",
    "print(\"There are {} data points in training data, each with {} attributes.\". format(num_records, num_attributes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81365da5-d652-4c94-9cb9-0bdbc430dc9e",
   "metadata": {},
   "source": [
    "### Load test data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "51b11652-d408-4b2d-b7a0-a39b1dafd5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique categories: 15\n",
      "Unique categories: {'parf car', 'opc car', 'electric cars', 'premium ad car', 'imported used vehicle', 'sgcarmart warranty cars', 'coe car', 'consignment car', 'direct owner sale', 'vintage cars', 'hybrid cars', 'sta evaluated car', 'almost new car', 'rare & exotic', 'low mileage car'}\n",
      "There are 24258 data points, each with 17 attributes.\n"
     ]
    }
   ],
   "source": [
    "test_file = './data/test.csv'\n",
    "df_test = pd.read_csv(test_file)\n",
    "\n",
    "df_test['reg_date'] = pd.to_datetime(df_test['reg_date'], format='%d-%b-%Y')\n",
    "df_test['reg_year'] = df_test['reg_date'].dt.year\n",
    "df_test = df_test.drop(columns=['reg_date'])\n",
    "\n",
    "# Replace '-' with an empty string\n",
    "df_test['category'] = df_test['category'].replace('-', '')\n",
    "\n",
    "# Split the 'category' column into lists\n",
    "df_test['category_list'] = df_test['category'].str.split(', ')\n",
    "\n",
    "# Handle empty strings by replacing them with empty lists\n",
    "df_test['category_list'] = df_test['category_list'].apply(lambda x: [] if x == [''] else x)\n",
    "\n",
    "# Import itertools for flattening lists\n",
    "from itertools import chain\n",
    "\n",
    "# Flatten the list of lists to a single list\n",
    "all_categories = list(chain.from_iterable(df_test['category_list']))\n",
    "\n",
    "# Get the unique categories\n",
    "unique_categories = set(all_categories)\n",
    "\n",
    "# Print the number of unique categories\n",
    "print(f\"Number of unique categories: {len(unique_categories)}\")\n",
    "print(\"Unique categories:\", unique_categories)\n",
    "\n",
    "# Initialize the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Fit and transform the category lists\n",
    "category_dummies = mlb.fit_transform(df_test['category_list'])\n",
    "\n",
    "# Create a DataFrame with the one-hot encoded categories\n",
    "category_df = pd.DataFrame(category_dummies, columns=mlb.classes_, index=df_test.index)\n",
    "\n",
    "# Concatenate the new dummy columns to the original DataFrame\n",
    "df_test = pd.concat([df_test, category_df], axis=1)\n",
    "\n",
    "# Drop the temporary 'category_list' column if desired\n",
    "df_test.drop('category_list', axis=1, inplace=True)\n",
    "df_test.drop('category', axis=1, inplace=True)\n",
    "\n",
    "num_records, num_attributes = df.shape\n",
    "\n",
    "print(\"There are {} data points, each with {} attributes.\". format(num_records, num_attributes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55faa8dc-6231-4b7d-b1de-bb0fc9405e03",
   "metadata": {},
   "source": [
    "### Data Augmentation, copy rows with less than 5 samples by group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "1ff32297-3b2c-4a56-94ae-4394247dcf4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 48306 data points after augmentation, each with 17 attributes.\n"
     ]
    }
   ],
   "source": [
    "from util.DataPreprocess import DataAugmentation\n",
    "\n",
    "df_aug = DataAugmentation(df)\n",
    "\n",
    "num_records, num_attributes = df_aug.shape\n",
    "print(\"There are {} data points after augmentation, each with {} attributes.\". format(num_records, num_attributes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e85bd5-970c-425c-a0f0-dce631a8d3a7",
   "metadata": {},
   "source": [
    "### Select attributes on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "6e21a079-8608-48b9-bd9e-389eb321d103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10000 data points, each with 43 attributes.\n",
      "There are 10000 data points in test data, each with 16 attributes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mileage</th>\n",
       "      <th>low mileage car</th>\n",
       "      <th>manufactured</th>\n",
       "      <th>reg_year</th>\n",
       "      <th>type_of_vehicle</th>\n",
       "      <th>dereg_value</th>\n",
       "      <th>depreciation</th>\n",
       "      <th>power</th>\n",
       "      <th>coe</th>\n",
       "      <th>arf</th>\n",
       "      <th>omv</th>\n",
       "      <th>road_tax</th>\n",
       "      <th>almost new car</th>\n",
       "      <th>coe car</th>\n",
       "      <th>parf car</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>705.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>9582.0</td>\n",
       "      <td>17660.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>57199</td>\n",
       "      <td>9229.0</td>\n",
       "      <td>19229.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>3</td>\n",
       "      <td>13644.0</td>\n",
       "      <td>10920.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>42564</td>\n",
       "      <td>15782.0</td>\n",
       "      <td>14347.0</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221.0</td>\n",
       "      <td>43000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>54818.0</td>\n",
       "      <td>22120.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>32801</td>\n",
       "      <td>47809.0</td>\n",
       "      <td>39863.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>707.0</td>\n",
       "      <td>53300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>26363.0</td>\n",
       "      <td>13700.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>29159</td>\n",
       "      <td>15573.0</td>\n",
       "      <td>15573.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>149000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>15197.0</td>\n",
       "      <td>14190.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>56001</td>\n",
       "      <td>13097.0</td>\n",
       "      <td>18097.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>389.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>40705.0</td>\n",
       "      <td>16830.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>41503</td>\n",
       "      <td>19388.0</td>\n",
       "      <td>19388.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>355.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>104529.0</td>\n",
       "      <td>21290.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>86000</td>\n",
       "      <td>39722.0</td>\n",
       "      <td>34087.0</td>\n",
       "      <td>586.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>46.0</td>\n",
       "      <td>163955.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>22004.0</td>\n",
       "      <td>12060.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>34935</td>\n",
       "      <td>42233.0</td>\n",
       "      <td>42233.0</td>\n",
       "      <td>1691.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>201.0</td>\n",
       "      <td>85473.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>28242.0</td>\n",
       "      <td>13720.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>30010</td>\n",
       "      <td>14799.0</td>\n",
       "      <td>14799.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>328.0</td>\n",
       "      <td>155385.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>14389.0</td>\n",
       "      <td>13570.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>34991</td>\n",
       "      <td>21692.0</td>\n",
       "      <td>21692.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model   mileage  low mileage car  manufactured  reg_year  \\\n",
       "0     705.0  112000.0                0        2015.0      2015   \n",
       "1      36.0  120000.0                1        2007.0      2007   \n",
       "2     221.0   43000.0                0        2019.0      2020   \n",
       "3     707.0   53300.0                0        2019.0      2019   \n",
       "4      36.0  149000.0                0        2015.0      2015   \n",
       "...     ...       ...              ...           ...       ...   \n",
       "9995  389.0   50000.0                0        2020.0      2020   \n",
       "9996  355.0    8500.0                1        2022.0      2023   \n",
       "9997   46.0  163955.0                0        2010.0      2010   \n",
       "9998  201.0   85473.0                0        2019.0      2020   \n",
       "9999  328.0  155385.0                1        2008.0      2008   \n",
       "\n",
       "      type_of_vehicle  dereg_value  depreciation  power    coe      arf  \\\n",
       "0                   8       9582.0       17660.0   96.0  57199   9229.0   \n",
       "1                   3      13644.0       10920.0   79.0  42564  15782.0   \n",
       "2                   6      54818.0       22120.0  141.0  32801  47809.0   \n",
       "3                   3      26363.0       13700.0   79.0  29159  15573.0   \n",
       "4                   1      15197.0       14190.0   88.0  56001  13097.0   \n",
       "...               ...          ...           ...    ...    ...      ...   \n",
       "9995                8      40705.0       16830.0  119.0  41503  19388.0   \n",
       "9996                8     104529.0       21290.0   96.0  86000  39722.0   \n",
       "9997                6      22004.0       12060.0  115.0  34935  42233.0   \n",
       "9998                3      28242.0       13720.0   93.0  30010  14799.0   \n",
       "9999                8      14389.0       13570.0  169.0  34991  21692.0   \n",
       "\n",
       "          omv  road_tax  almost new car  coe car  parf car  \n",
       "0     19229.0     682.0               0        0         1  \n",
       "1     14347.0    1113.0               0        1         0  \n",
       "2     39863.0    1210.0               0        0         1  \n",
       "3     15573.0     682.0               0        0         1  \n",
       "4     18097.0     682.0               0        0         1  \n",
       "...       ...       ...             ...      ...       ...  \n",
       "9995  19388.0     680.0               0        0         1  \n",
       "9996  34087.0     586.0               0        0         1  \n",
       "9997  42233.0    1691.0               0        1         0  \n",
       "9998  14799.0     738.0               0        0         1  \n",
       "9999  21692.0    2625.0               0        1         0  \n",
       "\n",
       "[10000 rows x 16 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_records, num_attributes = df_test.shape\n",
    "print(\"There are {} data points, each with {} attributes.\". format(num_records, num_attributes))\n",
    "\n",
    "categorical_columns = [\n",
    "    'make',\n",
    "    'model',\n",
    "    'type_of_vehicle',\n",
    "    'transmission',\n",
    "]\n",
    "\n",
    "with open('./data/encode.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for col, cate_dict in data.items():\n",
    "    if col in df_test.columns:\n",
    "        df_test[col] = df_test[col].map(cate_dict)\n",
    "\n",
    "df_test = df_test[columns_to_keep]\n",
    "\n",
    "num_records, num_attributes = df_test.shape\n",
    "print(\"There are {} data points in test data, each with {} attributes.\". format(num_records, num_attributes))\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "aa36cbc5-7c2c-473b-910e-8cfad5fc096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "\n",
    "def rf_fill_missing_values(df_train, df_test, n_neighbors=5):\n",
    "    combined_df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "    \n",
    "\n",
    "    if combined_df['manufactured'].isnull().any():\n",
    "        \n",
    "        known_manufactured = combined_df[combined_df['manufactured'].notna()]\n",
    "        unknown_manufactured = combined_df[combined_df['manufactured'].isna()]\n",
    "        \n",
    "      \n",
    "        rf_clf = RandomForestClassifier()\n",
    "        rf_clf.fit(known_manufactured.drop(columns=['manufactured']), known_manufactured['manufactured'])\n",
    "        \n",
    "        \n",
    "        combined_df.loc[unknown_manufactured.index, 'manufactured'] = rf_clf.predict(unknown_manufactured.drop(columns=['manufactured']))\n",
    "\n",
    "    numeric_features = ['mileage', 'dereg_value', 'depreciation', 'power', 'arf', 'omv', 'road_tax']\n",
    "    \n",
    "    for feature in numeric_features:\n",
    "        if combined_df[feature].isnull().any():\n",
    "            \n",
    "            known_data = combined_df[combined_df[feature].notna()]\n",
    "            unknown_data = combined_df[combined_df[feature].isna()]\n",
    "            \n",
    "        \n",
    "            X_train = known_data.drop(columns=numeric_features)\n",
    "            y_train = known_data[feature]\n",
    "            rf_model = RandomForestRegressor()\n",
    "            rf_model.fit(X_train, y_train)\n",
    "            \n",
    "            combined_df.loc[unknown_data.index, feature] = rf_model.predict(unknown_data.drop(columns=numeric_features))\n",
    "\n",
    "    df_test_filled = combined_df.loc[df_train.shape[0]:].reset_index(drop=True)\n",
    "\n",
    "    return df_test_filled\n",
    "\n",
    "df_test = rf_fill_missing_values(df_aug, df_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "21355c12-5cc1-479e-bad8-fde4ad098d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 98 null values\n",
      "price: 10000 null values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mileage</th>\n",
       "      <th>low mileage car</th>\n",
       "      <th>manufactured</th>\n",
       "      <th>reg_year</th>\n",
       "      <th>type_of_vehicle</th>\n",
       "      <th>dereg_value</th>\n",
       "      <th>depreciation</th>\n",
       "      <th>power</th>\n",
       "      <th>coe</th>\n",
       "      <th>arf</th>\n",
       "      <th>omv</th>\n",
       "      <th>price</th>\n",
       "      <th>road_tax</th>\n",
       "      <th>almost new car</th>\n",
       "      <th>coe car</th>\n",
       "      <th>parf car</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>705.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>9582.0</td>\n",
       "      <td>17660.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>57199</td>\n",
       "      <td>9229.0</td>\n",
       "      <td>19229.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>682.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>3</td>\n",
       "      <td>13644.0</td>\n",
       "      <td>10920.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>42564</td>\n",
       "      <td>15782.0</td>\n",
       "      <td>14347.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221.0</td>\n",
       "      <td>43000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>54818.0</td>\n",
       "      <td>22120.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>32801</td>\n",
       "      <td>47809.0</td>\n",
       "      <td>39863.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>707.0</td>\n",
       "      <td>53300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>26363.0</td>\n",
       "      <td>13700.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>29159</td>\n",
       "      <td>15573.0</td>\n",
       "      <td>15573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>682.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>149000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>15197.0</td>\n",
       "      <td>14190.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>56001</td>\n",
       "      <td>13097.0</td>\n",
       "      <td>18097.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>682.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>389.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>40705.0</td>\n",
       "      <td>16830.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>41503</td>\n",
       "      <td>19388.0</td>\n",
       "      <td>19388.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>680.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>355.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>104529.0</td>\n",
       "      <td>21290.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>86000</td>\n",
       "      <td>39722.0</td>\n",
       "      <td>34087.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>586.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>46.0</td>\n",
       "      <td>163955.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>22004.0</td>\n",
       "      <td>12060.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>34935</td>\n",
       "      <td>42233.0</td>\n",
       "      <td>42233.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1691.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>201.0</td>\n",
       "      <td>85473.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>28242.0</td>\n",
       "      <td>13720.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>30010</td>\n",
       "      <td>14799.0</td>\n",
       "      <td>14799.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>738.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>328.0</td>\n",
       "      <td>155385.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>14389.0</td>\n",
       "      <td>13570.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>34991</td>\n",
       "      <td>21692.0</td>\n",
       "      <td>21692.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model   mileage  low mileage car  manufactured  reg_year  \\\n",
       "0     705.0  112000.0                0        2015.0      2015   \n",
       "1      36.0  120000.0                1        2007.0      2007   \n",
       "2     221.0   43000.0                0        2019.0      2020   \n",
       "3     707.0   53300.0                0        2019.0      2019   \n",
       "4      36.0  149000.0                0        2015.0      2015   \n",
       "...     ...       ...              ...           ...       ...   \n",
       "9995  389.0   50000.0                0        2020.0      2020   \n",
       "9996  355.0    8500.0                1        2022.0      2023   \n",
       "9997   46.0  163955.0                0        2010.0      2010   \n",
       "9998  201.0   85473.0                0        2019.0      2020   \n",
       "9999  328.0  155385.0                1        2008.0      2008   \n",
       "\n",
       "      type_of_vehicle  dereg_value  depreciation  power    coe      arf  \\\n",
       "0                   8       9582.0       17660.0   96.0  57199   9229.0   \n",
       "1                   3      13644.0       10920.0   79.0  42564  15782.0   \n",
       "2                   6      54818.0       22120.0  141.0  32801  47809.0   \n",
       "3                   3      26363.0       13700.0   79.0  29159  15573.0   \n",
       "4                   1      15197.0       14190.0   88.0  56001  13097.0   \n",
       "...               ...          ...           ...    ...    ...      ...   \n",
       "9995                8      40705.0       16830.0  119.0  41503  19388.0   \n",
       "9996                8     104529.0       21290.0   96.0  86000  39722.0   \n",
       "9997                6      22004.0       12060.0  115.0  34935  42233.0   \n",
       "9998                3      28242.0       13720.0   93.0  30010  14799.0   \n",
       "9999                8      14389.0       13570.0  169.0  34991  21692.0   \n",
       "\n",
       "          omv  price  road_tax  almost new car  coe car  parf car  \n",
       "0     19229.0    NaN     682.0               0        0         1  \n",
       "1     14347.0    NaN    1113.0               0        1         0  \n",
       "2     39863.0    NaN    1210.0               0        0         1  \n",
       "3     15573.0    NaN     682.0               0        0         1  \n",
       "4     18097.0    NaN     682.0               0        0         1  \n",
       "...       ...    ...       ...             ...      ...       ...  \n",
       "9995  19388.0    NaN     680.0               0        0         1  \n",
       "9996  34087.0    NaN     586.0               0        0         1  \n",
       "9997  42233.0    NaN    1691.0               0        1         0  \n",
       "9998  14799.0    NaN     738.0               0        0         1  \n",
       "9999  21692.0    NaN    2625.0               0        1         0  \n",
       "\n",
       "[10000 rows x 17 columns]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_counts = df_test.isnull().sum()\n",
    "null_counts = null_counts[null_counts > 0]\n",
    "for column, count in null_counts.items():\n",
    "    print(f\"{column}: {count} null values\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd996336-d74b-4e21-b82a-dcd20d42cdcc",
   "metadata": {},
   "source": [
    "### Check if train data has all models in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d57e5e92-f7c4-454d-8653-d515f7754e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df does not include {nan}\n"
     ]
    }
   ],
   "source": [
    "models_in_df = set(df['model'].unique())\n",
    "models_in_df_test = set(df_test['model'].unique())\n",
    "\n",
    "if models_in_df_test.issubset(models_in_df):\n",
    "    print(\"df includes all models in df_test\")\n",
    "else:\n",
    "    missing_models = models_in_df_test - models_in_df\n",
    "    print(\"df does not include\", missing_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c681594f-3de4-4511-8154-437e10dee1b6",
   "metadata": {},
   "source": [
    "### Mining code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4c22a91f-729c-4a22-a443-0f05af43f099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.DataMining import split_dataframe, split_dataframe_flex\n",
    "from util.DataMining import (\n",
    "    RandomForestMining,\n",
    "    RandomForestMiningByModel,\n",
    "    GradientBoostingMining,\n",
    "    LinearRegressionMining,\n",
    "    LinearRegressionMiningByModel,\n",
    "    CombinedDataMiningRandomForestAndLinearRegression\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "03355739-324a-4a13-a77a-bf301417c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_times, rmse_sum = 5, 0\n",
    "# for i in tqdm(range(run_times), desc='Running Random Forest'):\n",
    "#     target_col = 'price'\n",
    "#     x_train, x_test, y_train, y_test = split_dataframe(df, target_col)\n",
    "#     rmse_sum += RandomForestMining(x_train, x_test, y_train, y_test)\n",
    "# print('Average RMSE:', round(rmse_sum / run_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "5469d35d-cf27-470e-97ab-9e4f0b67152d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Random Forest:   0%|                              | 0/1 [00:00<?, ?it/s]/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "Running Random Forest: 100%|██████████████████████| 1/1 [01:16<00:00, 76.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running not in develop mode\n",
      "RMSE on test data: 9016.710653884204\n",
      "Average RMSE: 9017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run_times, rmse_sum = 1, 0\n",
    "for i in tqdm(range(run_times), desc='Running Random Forest'):\n",
    "    train_drop_cols = ['price']\n",
    "    test_cols = ['price']\n",
    "    x_train, x_test, y_train, y_test = split_dataframe_flex(df_aug, train_drop_cols, test_cols)\n",
    "    rmse_sum += RandomForestMining(x_train, x_test, y_train, y_test)\n",
    "print('Average RMSE:', round(rmse_sum / run_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "9cfdbefc-a634-4be6-9efa-c7827e37ad3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Random Forest:   0%|                             | 0/10 [00:00<?, ?it/s]/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "Running Random Forest:  10%|██                   | 1/10 [01:18<11:42, 78.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running not in develop mode\n",
      "RMSE on test data: 7773.001991958654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "Running Random Forest:  20%|████▏                | 2/10 [02:35<10:20, 77.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running not in develop mode\n",
      "RMSE on test data: 8690.393032576465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "Running Random Forest:  30%|██████▎              | 3/10 [03:52<09:01, 77.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running not in develop mode\n",
      "RMSE on test data: 11930.154789281392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "Running Random Forest:  40%|████████▍            | 4/10 [05:10<07:45, 77.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running not in develop mode\n",
      "RMSE on test data: 10448.544003898936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "Running Random Forest:  50%|██████████▌          | 5/10 [06:28<06:28, 77.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running not in develop mode\n",
      "RMSE on test data: 8851.09939062025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "Running Random Forest:  60%|████████████▌        | 6/10 [07:45<05:10, 77.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running not in develop mode\n",
      "RMSE on test data: 13647.38690947743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "Running Random Forest:  70%|██████████████▋      | 7/10 [09:04<03:54, 78.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running not in develop mode\n",
      "RMSE on test data: 8096.338662675085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "Running Random Forest:  80%|████████████████▊    | 8/10 [10:22<02:35, 77.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running not in develop mode\n",
      "RMSE on test data: 8286.823095767924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "Running Random Forest:  90%|██████████████████▉  | 9/10 [11:39<01:17, 77.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running not in develop mode\n",
      "RMSE on test data: 12214.253363442933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "Running Random Forest: 100%|████████████████████| 10/10 [12:56<00:00, 77.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running not in develop mode\n",
      "RMSE on test data: 10462.550723668974\n",
      "Average RMSE: 10040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import joblib  \n",
    "from tqdm import tqdm\n",
    "\n",
    "run_times, rmse_sum = 10, 0\n",
    "best_model = None  \n",
    "best_rmse = float('inf')  \n",
    "\n",
    "for i in tqdm(range(run_times), desc='Running Random Forest'):\n",
    "    train_drop_cols = ['price']\n",
    "    test_cols = ['price', 'model']\n",
    "    x_train, x_test, y_train, y_test = split_dataframe_flex(df_aug, train_drop_cols, test_cols)\n",
    "    \n",
    "    \n",
    "    rf_model, rmse = RandomForestMiningByModel(x_train, x_test, y_train, y_test)  \n",
    "    \n",
    "    rmse_sum += rmse  # \n",
    "\n",
    "    \n",
    "    if rmse < best_rmse:  \n",
    "        best_rmse = rmse\n",
    "        best_model = rf_model  \n",
    "        joblib.dump(rf_model, 'best_random_forest_bymodel.pkl')  \n",
    "\n",
    "print('Average RMSE:', round(rmse_sum / run_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4229aeee-e40d-4332-aab2-82beceb910a1",
   "metadata": {},
   "source": [
    "### This cell do prediction model by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "900b06eb-489d-40c2-8722-61bcd5fd87a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Documents/cs5228/CS5228_Project-mining_zijie/util/DataMining.py:120: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  y_pred = pd.concat([y_pred, temp_df])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     19266.235\n",
      "1     33973.670\n",
      "2    143551.660\n",
      "3     72275.440\n",
      "4     27777.800\n",
      "Name: Predicted, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = df_aug.drop(columns=['price']), df_aug[['price', 'model']]\n",
    "x_test = df_test[x_train.columns].dropna(subset=['model'])\n",
    "\n",
    "res_model = RandomForestMiningByModel(x_train, x_test, y_train, dev=True)\n",
    "print(res_model.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b1c5d2-e091-44e2-ab66-c4ef272ab0a6",
   "metadata": {},
   "source": [
    "### This cell do prediction on test data with 'model' attribute missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "ee95f3a0-b95a-463e-ad61-e8865d6f02d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Predicted\n",
      "21    60852.033916\n",
      "195  285878.964933\n",
      "212  187558.266407\n",
      "402   20210.401628\n",
      "412  103300.378208\n"
     ]
    }
   ],
   "source": [
    "df_test_unmapped = df_test[df_test['model'].isna()]\n",
    "x_train, y_train = df_aug.drop(columns=['price', 'model']), df_aug[['price']]\n",
    "x_test = df_test_unmapped[x_train.columns]\n",
    "\n",
    "res_nomodel = RandomForestMining(x_train, x_test, y_train, dev=True)\n",
    "print(res_nomodel.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "89a93b02-347e-45fb-82bd-b1627555e72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9902\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "print(len(res_model))\n",
    "print(len(res_nomodel))\n",
    "res = pd.concat([res_model, res_nomodel])\n",
    "res.to_csv('./data/res_by_model_original.csv')\n",
    "res.reset_index(inplace=True)\n",
    "res.rename(columns={'index': 'Id'}, inplace=True)\n",
    "res_sorted = res.sort_values(by='Id')\n",
    "res_sorted.to_csv('./data/res_by_model2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387f2301-f281-4dfc-b417-c3966a2fe6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
