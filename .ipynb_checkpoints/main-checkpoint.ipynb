{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9139239be4d3d26a",
   "metadata": {},
   "source": [
    "<img src=\"images/img.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a5ce1aa953b915",
   "metadata": {},
   "source": [
    "# CS5228 Project, Group 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f32f076115be79",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "In this part, we are going to perform some data preprocessing steps. This may include:\n",
    "* Data cleaning: handle missing values, duplicates, inconsistant or invalid vallues, outliers\n",
    "\n",
    "* Data reduction: reduce number of attributes, reduce number of attribute values\n",
    "\n",
    "* Data transformation: attribute construction, normalization\n",
    "\n",
    "* Data discretization: encode to numerical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773fb74f",
   "metadata": {},
   "source": [
    "### Setting up the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a8c6d3e9adfc751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a084ae15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 25000 data points in training data, each with 30 attributes.\n",
      "There are 10000 data points in test data, each with 29 attributes.\n"
     ]
    }
   ],
   "source": [
    "# Load file into pandas dataframe\n",
    "df = pd.read_csv('./data/train.csv')\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "num_records, num_attributes = df.shape\n",
    "print(\"There are {} data points in training data, each with {} attributes.\". format(num_records, num_attributes))\n",
    "num_records, num_attributes = df_test.shape\n",
    "print(\"There are {} data points in test data, each with {} attributes.\". format(num_records, num_attributes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd41045",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389b04ed",
   "metadata": {},
   "source": [
    "Before data cleaning, remove the known attributes that are not meaningful to our prediction model:\n",
    "  * Meaningless idendifier: listing_id \n",
    "  * Attributes in free text: title, description, features, accessories\n",
    "  * Attribute with the same value: eco_category, indicative_price\n",
    "  * Attribute unlikely to affect price: curb_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c02d46d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 25000 data points, each with 20 attributes.\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [\n",
    "    'listing_id',          # Meaningless identifier\n",
    "    'title',               # Attributes in free text\n",
    "    'description',\n",
    "    'features',\n",
    "    'accessories',\n",
    "    'eco_category',        # Attribute with the same value\n",
    "    'indicative_price',\n",
    "    'curb_weight',         # Attribute unlikely to affect price\n",
    "\n",
    "    'original_reg_date',\n",
    "    'lifespan',\n",
    "]\n",
    "\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "num_records, num_attributes = df.shape\n",
    "print(\"There are {} data points, each with {} attributes.\". format(num_records, num_attributes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde0aaf8",
   "metadata": {},
   "source": [
    "### Handle Missing Values\n",
    "Firstly, for each of the columns with missing value, check the number of rows with NaN values.\n",
    "There are 3 scenarios:\n",
    "1. NaN value is the major (e.g. fuel_type has 19121 rows with NaN values), we remove the corresponding attritubes.\n",
    "2. NaN value is the minor. We can choose to fill or delete related data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "834807be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'make' has 1316 rows with NaN values.\n",
      "Column 'fuel_type' has 19121 rows with NaN values.\n",
      "Column 'manufactured' has 7 rows with NaN values.\n",
      "Column 'power' has 2640 rows with NaN values.\n",
      "Column 'engine_cap' has 596 rows with NaN values.\n",
      "Column 'mileage' has 5304 rows with NaN values.\n",
      "Column 'no_of_owners' has 18 rows with NaN values.\n",
      "Column 'depreciation' has 507 rows with NaN values.\n",
      "Column 'road_tax' has 2632 rows with NaN values.\n",
      "Column 'dereg_value' has 220 rows with NaN values.\n",
      "Column 'omv' has 64 rows with NaN values.\n",
      "Column 'arf' has 174 rows with NaN values.\n",
      "Column 'opc_scheme' has 24838 rows with NaN values.\n"
     ]
    }
   ],
   "source": [
    "columns_to_check = [\n",
    "    'make',\n",
    "    'fuel_type',\n",
    "    'manufactured',\n",
    "    'power',\n",
    "    'engine_cap',\n",
    "    'mileage',\n",
    "    'no_of_owners',\n",
    "    'depreciation',\n",
    "    'road_tax',\n",
    "    'dereg_value',\n",
    "    'omv',\n",
    "    'arf',\n",
    "    'opc_scheme'\n",
    "]\n",
    "\n",
    "# Calculate the number of NaN values in each specified column\n",
    "nan_counts = df[columns_to_check].isna().sum()\n",
    "\n",
    "# Print the number of NaN values for each column\n",
    "for column, count in nan_counts.items():\n",
    "    print(f\"Column '{column}' has {count} rows with NaN values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116b0e50",
   "metadata": {},
   "source": [
    "We delete attributes with TOO many NaN value here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da6b4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop_nan = [\n",
    "    'fuel_type',\n",
    "    'opc_scheme'\n",
    "]\n",
    "\n",
    "df = df.drop(columns=columns_to_drop_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea8a0de",
   "metadata": {},
   "source": [
    "Then we try to fill up other missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfc6a526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values after handling:  0\n"
     ]
    }
   ],
   "source": [
    "from util.DataPreprocess import HandlingMissingValues\n",
    "\n",
    "df = HandlingMissingValues(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eafaf03",
   "metadata": {},
   "source": [
    "### Remove Exact Duplicates\n",
    "We remove duplicated data points here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8caa0e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24258 data points, each with 18 attributes.\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df_test = df_test.drop_duplicates()\n",
    "\n",
    "num_records, num_attributes = df.shape\n",
    "print(\"There are {} data points, each with {} attributes.\". format(num_records, num_attributes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84de8476-6545-4f89-ad57-b891986a9045",
   "metadata": {},
   "source": [
    "### Merge rows with fewer data points on specific attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3a7ec8a-8007-4aec-b501-2b4bfb4192ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 2\n",
    "\n",
    "value_counts = df['make'].value_counts()\n",
    "categories_to_replace = value_counts[value_counts < threshold].index\n",
    "df['make'] = df['make'].replace(categories_to_replace, 'others')\n",
    "\n",
    "value_counts = df_test['make'].value_counts()\n",
    "categories_to_replace = value_counts[value_counts < threshold].index\n",
    "df_test['make'] = df_test['make'].replace(categories_to_replace, 'others')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28900a18-8bf3-4516-b663-c00533fde54f",
   "metadata": {},
   "source": [
    "### Transform categorical value to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "829f7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    'make',\n",
    "    'model',\n",
    "    'type_of_vehicle',\n",
    "    'transmission',\n",
    "]\n",
    "\n",
    "le = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "    df_test[column] = le.fit_transform(df_test[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a273d568",
   "metadata": {},
   "source": [
    "### Transform date time attributes to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f580a7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24258 data points, each with 18 attributes.\n"
     ]
    }
   ],
   "source": [
    "df['reg_date'] = pd.to_datetime(df['reg_date'], format='%d-%b-%Y')\n",
    "df['reg_year'] = df['reg_date'].dt.year\n",
    "df = df.drop(columns=['reg_date'])\n",
    "\n",
    "num_records, num_attributes = df.shape\n",
    "\n",
    "print(\"There are {} data points, each with {} attributes.\". format(num_records, num_attributes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a29cd1d",
   "metadata": {},
   "source": [
    "### Handle category attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a43ae4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique categories: 15\n",
      "Unique categories: {'direct owner sale', 'parf car', 'hybrid cars', 'low mileage car', 'sgcarmart warranty cars', 'electric cars', 'imported used vehicle', 'coe car', 'sta evaluated car', 'consignment car', 'opc car', 'premium ad car', 'almost new car', 'vintage cars', 'rare & exotic'}\n",
      "There are 24258 data points, each with 32 attributes.\n"
     ]
    }
   ],
   "source": [
    "# Replace '-' with an empty string\n",
    "df['category'] = df['category'].replace('-', '')\n",
    "\n",
    "# Split the 'category' column into lists\n",
    "df['category_list'] = df['category'].str.split(', ')\n",
    "\n",
    "# Handle empty strings by replacing them with empty lists\n",
    "df['category_list'] = df['category_list'].apply(lambda x: [] if x == [''] else x)\n",
    "\n",
    "# Import itertools for flattening lists\n",
    "from itertools import chain\n",
    "\n",
    "# Flatten the list of lists to a single list\n",
    "all_categories = list(chain.from_iterable(df['category_list']))\n",
    "\n",
    "# Get the unique categories\n",
    "unique_categories = set(all_categories)\n",
    "\n",
    "# Print the number of unique categories\n",
    "print(f\"Number of unique categories: {len(unique_categories)}\")\n",
    "print(\"Unique categories:\", unique_categories)\n",
    "\n",
    "# Initialize the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Fit and transform the category lists\n",
    "category_dummies = mlb.fit_transform(df['category_list'])\n",
    "\n",
    "# Create a DataFrame with the one-hot encoded categories\n",
    "category_df = pd.DataFrame(category_dummies, columns=mlb.classes_, index=df.index)\n",
    "\n",
    "# Concatenate the new dummy columns to the original DataFrame\n",
    "df = pd.concat([df, category_df], axis=1)\n",
    "\n",
    "# Drop the temporary 'category_list' column if desired\n",
    "df.drop('category_list', axis=1, inplace=True)\n",
    "df.drop('category', axis=1, inplace=True)\n",
    "\n",
    "num_records, num_attributes = df.shape\n",
    "\n",
    "print(\"There are {} data points, each with {} attributes.\". format(num_records, num_attributes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11789885",
   "metadata": {},
   "source": [
    "### Saving the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10b15971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing file './data/train_preprocessed.csv' has been deleted.\n",
      "DataFrame has been saved to './data/train_preprocessed.csv'.\n"
     ]
    }
   ],
   "source": [
    "file_name = './data/train_preprocessed.csv'\n",
    "# file_name = '../data/preprocessed/test_preprocessed.csv'\n",
    "\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_name):\n",
    "    # Delete the file\n",
    "    os.remove(file_name)\n",
    "    print(f\"Existing file '{file_name}' has been deleted.\")\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "df.to_csv(file_name, index=False)\n",
    "print(f\"DataFrame has been saved to '{file_name}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bc5a63",
   "metadata": {},
   "source": [
    "## Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519d3338-4cee-4020-bcf8-c94f84c1d944",
   "metadata": {},
   "source": [
    "### We load our preprocessed data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6e80ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24258 data points in training data, each with 8 attributes.\n",
      "There are 10000 data points in test data, each with 7 attributes.\n"
     ]
    }
   ],
   "source": [
    "# Load file into pandas dataframe, we saved our preprocessed file at path 'output_file'\n",
    "output_file = './data/train_preprocessed.csv'\n",
    "df = pd.read_csv(output_file)\n",
    "\n",
    "columns_to_keep = [\n",
    "    'model',\n",
    "    'dereg_value',\n",
    "    'arf',\n",
    "    'omv',\n",
    "    'depreciation',\n",
    "    'power',\n",
    "    'coe',\n",
    "    'price',\n",
    "]\n",
    "\n",
    "df = df[columns_to_keep]\n",
    "columns_to_keep = [col for col in df.columns if col != 'price']\n",
    "df_test = df_test[columns_to_keep]\n",
    "\n",
    "num_records, num_attributes = df.shape\n",
    "print(\"There are {} data points in training data, each with {} attributes.\". format(num_records, num_attributes))\n",
    "num_records, num_attributes = df_test.shape\n",
    "print(\"There are {} data points in test data, each with {} attributes.\". format(num_records, num_attributes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c681594f-3de4-4511-8154-437e10dee1b6",
   "metadata": {},
   "source": [
    "### Mining code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c22a91f-729c-4a22-a443-0f05af43f099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.DataMining import split_dataframe, split_dataframe_flex\n",
    "from util.DataMining import RandomForestMining\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "751f8892-175a-4cd0-8024-436d31241bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search， running these code lines take about 30 minutes\n",
    "search_grid = False\n",
    "if search_grid:\n",
    "    param_grid = {'max_depth': range(1, 21)}\n",
    "    grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    print(\"Best max_depth:\", grid_search.best_params_['max_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dca4085-f34f-4789-a4ac-6195f9f271da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Random Forest:  10%|█████████▏                                                                                  | 1/10 [00:21<03:15, 21.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running not in develop mode\n",
      "RMSE on test data: 26831.35310417431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Random Forest:  20%|██████████████████▍                                                                         | 2/10 [00:43<02:53, 21.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running not in develop mode\n",
      "RMSE on test data: 21356.468910706317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Random Forest:  30%|███████████████████████████▌                                                                | 3/10 [01:04<02:30, 21.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running not in develop mode\n",
      "RMSE on test data: 22463.448459248386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Random Forest:  40%|████████████████████████████████████▊                                                       | 4/10 [01:26<02:09, 21.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running not in develop mode\n",
      "RMSE on test data: 18703.78398895981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Random Forest:  50%|██████████████████████████████████████████████                                              | 5/10 [01:47<01:47, 21.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running not in develop mode\n",
      "RMSE on test data: 37058.27806267251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Random Forest:  60%|███████████████████████████████████████████████████████▏                                    | 6/10 [02:09<01:26, 21.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running not in develop mode\n",
      "RMSE on test data: 24403.455874692758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Random Forest:  70%|████████████████████████████████████████████████████████████████▍                           | 7/10 [02:30<01:04, 21.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running not in develop mode\n",
      "RMSE on test data: 20795.48500747697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Random Forest:  80%|█████████████████████████████████████████████████████████████████████████▌                  | 8/10 [02:52<00:42, 21.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running not in develop mode\n",
      "RMSE on test data: 21637.362161735087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Random Forest:  90%|██████████████████████████████████████████████████████████████████████████████████▊         | 9/10 [03:13<00:21, 21.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running not in develop mode\n",
      "RMSE on test data: 22595.62584420286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Random Forest: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:34<00:00, 21.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running not in develop mode\n",
      "RMSE on test data: 19426.57701484216\n",
      "Average RMSE: 1943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Running algo. not in development mode, i.e. just train and test on the given training set\n",
    "run_times, rmse_sum = 10, 0\n",
    "for i in tqdm(range(run_times), desc='Running Random Forest'):\n",
    "    target_col = 'price'\n",
    "    x_train, x_test, y_train, y_test = split_dataframe(df, target_col)\n",
    "    rmse_sum += RandomForestMining(x_train, x_test, y_train, y_test)\n",
    "print('Average RMSE:', round(rmse_sum / run_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d92195fa-65a3-4dfd-8227-2418757391db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running algo. in development mode, i.e. train and give final result\n",
    "result_path = './data/res2.csv'\n",
    "target_col = 'price'\n",
    "X_train, X_test, y_train = df.drop(columns='price'), df_test, df['price']\n",
    "pred = RandomForestMining(X_train, X_test, y_train, dev=True)\n",
    "\n",
    "dir_path = os.path.dirname(result_path)\n",
    "if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)\n",
    "pred.to_csv(result_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b65655-b544-4663-a7a7-6478dfbda6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abd63ab-5f2b-48fe-8a7d-6d9563ac6154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8197ee9a-87c5-43a6-b7c9-29740ab84bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
